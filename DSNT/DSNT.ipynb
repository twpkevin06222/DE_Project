{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable Spatial to Numerical Transform (DSNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dummy implementation of DSNT layer from the paper \"Numerical Coordinate Regression with Convolutional Neural Networks\" by Aiden Nibali, Zhen He, Stuart Morgan, Luke Prendergast. Link: https://arxiv.org/abs/1801.07372\n",
    "\n",
    "- Main references: https://github.com/ashwhall/dsnt/blob/master/DSNT_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "200 images total\n",
      "training: 150\n",
      "testing : 50\n"
     ]
    }
   ],
   "source": [
    "img_size = 150\n",
    "image_count = 200 #number of images \n",
    "train_percent = 0.75\n",
    "train_image_count = int(train_percent * image_count)\n",
    "test_image_count = image_count - train_image_count\n",
    "\n",
    "images = []\n",
    "targets = [] #centroid coordinates of circle \n",
    "for _ in range(200):\n",
    "    img = np.zeros((img_size, img_size, 3))\n",
    "    row, col = np.random.randint(0, img_size), np.random.randint(0, img_size)\n",
    "    radius = np.random.randint(8, 15)\n",
    "    b, g, r = np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255)\n",
    "    cv2.circle(img, (row, col), radius, (b, g, r), -1)\n",
    "    images.append(img)\n",
    "    norm_row = row / img_size\n",
    "    norm_col = col / img_size\n",
    "    targets.append([norm_row, norm_col])\n",
    "\n",
    "images = np.array(images, dtype = 'float32')\n",
    "#normalize image:\n",
    "images = images/255.0\n",
    "targets = np.array(targets, dtype = 'float32')\n",
    "train_images = images[:train_image_count]\n",
    "test_images = images[train_image_count:]\n",
    "train_targets = targets[:train_image_count]\n",
    "test_targets = targets[train_image_count:]\n",
    "\n",
    "print('''\n",
    "{} images total\n",
    "training: {}\n",
    "testing : {}'''.format(image_count, train_image_count, test_image_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize image:\n",
    "for i in range(len(images)):\n",
    "    plt.imshow(images[i])\n",
    "    plt.show()\n",
    "    break\n",
    "    \n",
    "#     if input()==\"exit\":\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using dilated convolutional layers, each time downsampling by a factor of 2. The network finishes with a kernel-size 1 convolution, producing a single channel heat-map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Sequential \n",
    "from tensorflow.keras.layers import Conv2D, ReLU, Dense, Flatten \n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "import dsnt #https://github.com/ashwhall/dsnt/blob/master/dsnt.py\n",
    "\n",
    "#to do Coordconv implementation\n",
    "class model(Model):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        self.inference_net = Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(150, 150, 3)),\n",
    "            Conv2D(filters = 166, kernel_size = 3, strides = 1, \n",
    "                    padding = \"same\", dilation_rate = 1,  \n",
    "                   activation = 'relu'), \n",
    "            MaxPooling2D(pool_size = 2, strides = 2, padding = 'same'),\n",
    "\n",
    "            Conv2D(filters = 32, kernel_size = 3, strides = 1, \n",
    "                    padding = \"same\", dilation_rate = 2,  \n",
    "                   activation = 'relu'), \n",
    "            MaxPooling2D(pool_size = 2, strides = 2, padding = 'same'),\n",
    "\n",
    "            Conv2D(filters = 64, kernel_size = 3, strides = 1, \n",
    "                    padding = \"same\", dilation_rate = 4,  \n",
    "                   activation = 'relu'), \n",
    "            MaxPooling2D(pool_size = 2, strides = 2, padding = 'same'),\n",
    "\n",
    "            Conv2D(filters = 128, kernel_size = 3, strides = 1, \n",
    "                    padding = \"same\", dilation_rate = 8,  \n",
    "                   activation = 'relu'), \n",
    "            MaxPooling2D(pool_size = 2, strides = 2, padding = 'same'),\n",
    "\n",
    "            Conv2D(filters = 256, kernel_size = 3, strides = 1, \n",
    "                    padding = \"same\", dilation_rate = 16,  \n",
    "                   activation = 'relu'), \n",
    "            MaxPooling2D(pool_size = 2, strides = 2, padding = 'same'),\n",
    "\n",
    "            Conv2D(filters = 256, kernel_size = 3, strides = 1, \n",
    "                    padding = \"same\", dilation_rate = 1,  \n",
    "                   activation = 'relu'), \n",
    "            MaxPooling2D(pool_size = 2, strides = 2, padding = 'same'),\n",
    "\n",
    "            Conv2D(filters = 1, kernel_size = 1, strides = 1, \n",
    "                    padding = \"same\"),  \n",
    "        ])\n",
    "    \n",
    "    def output(self, inp):\n",
    "        inference = self.inference_net(inp)\n",
    "        norm_heatmap, coords = dsnt.dsnt(inference)\n",
    "        \n",
    "        return norm_heatmap, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_STEP = 5000\n",
    "lr = 6e-5\n",
    "\n",
    "model = model()\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((train_images, train_targets)).shuffle(10000).repeat(100).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d_6/BiasAdd:0\", shape=(None, 3, 3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Loss: 0.6986120939254761\n",
      "Step: 100, Loss: 0.2570840120315552\n",
      "Step: 200, Loss: 0.21254737675189972\n",
      "Step: 300, Loss: 0.19615352153778076\n",
      "Step: 400, Loss: 0.1734514683485031\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "def loss_fn(model, imgs, lbls):\n",
    "    heatmaps, predictions = model.output(imgs)\n",
    "    #coordinate regression loss\n",
    "    #loss_1 = tf.reduce_mean(tf.square(lbls - predictions))\n",
    "    loss_1 = mse(lbls, predictions)\n",
    "    #Regularization loss\n",
    "    loss_2 = dsnt.js_reg_loss(heatmaps, lbls)\n",
    "    Loss_total = loss_1 + loss_2\n",
    "    \n",
    "    return Loss_total, heatmaps, predictions\n",
    "    \n",
    "@tf.function\n",
    "def train_fn(imgs, lbls):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, heatmaps, predictions = loss_fn(model, imgs, lbls)        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, heatmaps, predictions\n",
    "\n",
    "loss_list = []\n",
    "heatmaps_list = []\n",
    "predictions_list = []\n",
    "img_list = []\n",
    "lbl_list = []\n",
    "for steps, (img_batch, lbl_batch) in enumerate(ds_train):\n",
    "    if steps > MAX_STEP:\n",
    "        print('End of steps!')\n",
    "        break\n",
    "\n",
    "    loss, heatmaps, predictions = train_fn(img_batch, lbl_batch)\n",
    "    \n",
    "    Template = 'Step: {}, Loss: {}'\n",
    "\n",
    "    if not steps % 100:\n",
    "        loss_list.append(loss)\n",
    "        heatmaps_list.append(heatmaps)\n",
    "        predictions_list.append(predictions)\n",
    "        img_list.append(img_batch)\n",
    "        lbl_list.append(lbl_batch)\n",
    "        \n",
    "        print(Template.format(steps, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0076892423, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sums = 0\n",
    "\n",
    "for value in loss_list:\n",
    "    sums += value\n",
    "print(sums/ image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.asarray(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.11699104e-04, -1.82457268e-04],\n",
       "       [-4.26173210e-06, -3.97115946e-05],\n",
       "       [ 1.14336610e-04,  2.11223960e-05],\n",
       "       [-6.90519810e-05, -2.26743519e-04],\n",
       "       [-1.15737319e-04, -1.62012875e-04],\n",
       "       [-7.90581107e-05, -8.05333257e-05],\n",
       "       [-1.17033720e-04, -2.57655978e-04],\n",
       "       [ 1.01372600e-04, -4.64767218e-05],\n",
       "       [-1.28597021e-05, -1.68591738e-04],\n",
       "       [ 6.78673387e-05, -7.15255737e-07],\n",
       "       [-1.19879842e-04, -1.46284699e-04],\n",
       "       [-2.11447477e-05, -2.17579305e-04],\n",
       "       [ 3.07187438e-05, -1.76355243e-05],\n",
       "       [ 9.04574990e-05,  1.89542770e-05],\n",
       "       [-1.84997916e-05, -5.68479300e-05],\n",
       "       [ 1.84774399e-05, -3.46004963e-05],\n",
       "       [-6.61611557e-06,  9.80198383e-05],\n",
       "       [-1.13099813e-05, -1.62303448e-04],\n",
       "       [ 5.28991222e-06, -1.62377954e-04],\n",
       "       [-5.16772270e-05, -1.71676278e-04],\n",
       "       [-1.24782324e-04, -2.35438347e-05],\n",
       "       [-6.99982047e-05, -1.26332045e-04],\n",
       "       [-2.49207020e-04, -3.00273299e-04],\n",
       "       [ 1.19544566e-04, -9.91523266e-05],\n",
       "       [ 5.91948628e-05, -1.04635954e-04],\n",
       "       [-1.63242221e-05, -2.20999122e-04],\n",
       "       [-7.59884715e-05, -7.79703259e-05],\n",
       "       [-8.01160932e-05, -1.81823969e-04],\n",
       "       [-5.02467155e-05, -1.02743506e-04],\n",
       "       [-5.15505672e-05, -7.90581107e-05],\n",
       "       [ 3.42726707e-06, -7.88867474e-05],\n",
       "       [ 4.79742885e-05, -4.74750996e-05]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.asarray(heatmaps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_array= tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11102127, 0.11127149, 0.11119885],\n",
       "       [0.11105724, 0.11113539, 0.11109786],\n",
       "       [0.11110848, 0.1110516 , 0.11105783]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_array[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
