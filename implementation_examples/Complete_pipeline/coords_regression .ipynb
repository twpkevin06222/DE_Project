{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/kevinteng/Desktop/DE_Project')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Softmax, MaxPooling2D\n",
    "from coord_conv import CoordConv\n",
    "import utils\n",
    "import utils_vis\n",
    "import utils_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_regression(inps): \n",
    "    coord01 = CoordConv(x_dim = 100, y_dim = 100, with_r = False, filters = 20, \n",
    "              kernel_size = 1)(inps)\n",
    "    conv01 = Conv2D(20,1, activation = None)(coord01) \n",
    "    conv02 = Conv2D(20,1, activation = None)(conv01)\n",
    "    conv03 = Conv2D(20,1, activation = None)(conv02)\n",
    "    conv04 = Conv2D(20,1, activation = None)(conv03) \n",
    "    conv05 = Conv2D(20,1, activation = None)(conv04) \n",
    "    conv06 = Conv2D(20,3, activation = None)(conv05) \n",
    "    conv07 = Conv2D(2,3 ,activation = None)(conv06) \n",
    "    output = MaxPooling2D( pool_size= 96, strides = 96, padding='valid')(conv07)\n",
    "    return output \n",
    "\n",
    "def de_conv(input_tensor):\n",
    "    coord01 = CoordConv(x_dim = 100, y_dim = 100, with_r = False, filters = 100,\n",
    "              kernel_size = 1, padding='same', activation='relu')(input_tensor)\n",
    "    conv01 = Conv2D(filters = 50, kernel_size = 1, strides = 1, padding = \"same\", activation = 'relu')(coord01)\n",
    "    conv02 = Conv2D(filters = 50, kernel_size = 1, strides = 1, padding = \"same\", activation = 'relu')(conv01)\n",
    "    conv03 = Conv2D(filters = 100, kernel_size = 1, strides = 1, padding = \"same\", activation = 'relu')(conv02)\n",
    "    conv04 = Conv2D(filters = 100, kernel_size = 1, strides = 1, padding = \"same\", activation = 'relu')(conv03)\n",
    "    conv05 = Conv2D(filters = 1, kernel_size = 1, strides = 1, padding = \"same\" )(conv04)\n",
    "    f1 = Flatten()(conv05)\n",
    "    output = Softmax(axis = -1)(f1)\n",
    "    return output\n",
    "\n",
    "def latent_space(encoded_imgs, deconv_imgs, coords, batch_size, img_size):\n",
    "    '''\n",
    "    This function construct the dot product of the output of an encoder(batch_size, img_size, img_size, 1) \n",
    "    with the one hot images generated by decoord-conv(n_neurons, img_size, img_size, 1), which yields\n",
    "    similarity score (batch_size, n_neurons). Similarity score is then concatenate to the last layer of the \n",
    "    input coordinates with the corresponding batch (batch_size, n_neurons, 3)\n",
    "    \n",
    "    @encoded_imgs: output images from the encoder\n",
    "    @deconv_imgs: one hot images generated from the coordinate list \n",
    "    @coords: A list of coordinates generated randomly based on the number of neurons\n",
    "    @batch_size: Batch size of the input image for encoder, to allocate size for writing in loop\n",
    "    \n",
    "    return: \n",
    "        latent space with dim (batch_size, n_neurons, 3, 1)\n",
    "    '''\n",
    "    similarity_score = tf.tensordot(encoded_imgs, deconv_imgs, [[1,2,3],[1,2,3]]) #(batch_size, n_neurons)\n",
    "    squeeze_coords = tf.squeeze(coords/(img_size-1)) #coords dim (n_neurons, 1, 1, 2) = > (n_neurons, 2)\n",
    "    latent = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "    for i in tf.range(batch_size):\n",
    "        concat = tf.stack((squeeze_coords[:,-2], squeeze_coords[:,-1], similarity_score[i]), axis=-1)    \n",
    "        latent = latent.write(i, concat) #(batch_size, n_neurons, 3)\n",
    "    return tf.expand_dims(latent.stack(), axis = -1), similarity_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = 2\n",
    "IMG_SIZE = 100\n",
    "BATCH_SIZE = 8\n",
    "lr=0.1\n",
    "\n",
    "neuron_imgs_list = []\n",
    "coords,_, ori_one_hot_imgs = utils_model.create_dat_samples(n_neurons, IMG_SIZE)\n",
    "coords = tf.reshape(coords, [n_neurons, 1,1,2]) #for the input shape of deconv \n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    neuron_imgs = tf.squeeze(utils_model.neuron_like_image(n_neurons, IMG_SIZE))\n",
    "    neuron_imgs_list.append(neuron_imgs)\n",
    "neuron_imgs_list = tf.expand_dims(tf.convert_to_tensor(neuron_imgs_list), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build coord-deconv model\n",
    "inp = Input(shape=(100, 100,2)) #(batch_size, img_size, img_size, 2)\n",
    "de_coordconv = Model(inp, de_conv(inp))\n",
    "de_coordconv.load_weights(\"best_class_model100_02.hdf5\")\n",
    "\n",
    "#build reg model\n",
    "model_input = Input(shape=(100,100,1))\n",
    "coordconv = Model(model_input, model_regression(model_input))\n",
    "coordconv.load_weights(\"best_reg_model100_02.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function \n",
    "mse = tf.losses.MeanSquaredError()\n",
    "def test_fn(inp_imgs, coords, img_size):\n",
    "    norm_coords = coords/(img_size-1)\n",
    "    m1 = tf.constant([1,img_size, img_size,1], tf.int32) #multiplier for tiling \n",
    "    tile_cd = tf.tile(norm_coords, m1)\n",
    "    #deconv\n",
    "    de_coordconv.trainable = False #freeze de-coordconv\n",
    "    one_hot_imgs = tf.reshape(de_coordconv(tile_cd), [-1, img_size, img_size, 1])\n",
    "    #dot product\n",
    "    similarity_score = tf.tensordot(inp_imgs, one_hot_imgs, [[1,2,3],[1,2,3]])\n",
    "    #multiply similarity scores with one hot images\n",
    "    similarity_multi = tf.einsum('ij,jklm->ijklm', similarity_score, one_hot_imgs) #(batch_size, n_neurons, img_size, img_size,1)\n",
    "    #sum the one hot images for all neurons to compute MSE\n",
    "    similarity_multi_reduced_neurons = tf.reduce_sum(similarity_multi, axis=1)#(batch_size, img_size, img_size, 1)\n",
    "    similarity_multi_max_batch = tf.reduce_max(similarity_multi, axis = 0)#(n_neurons,img_size,mg_size,1)\n",
    "    #generate coordinates from coordconv model \n",
    "    coordconv.trainable = True \n",
    "    generate_coords = coordconv(similarity_multi_max_batch)\n",
    "    #reconstruciton loss \n",
    "    loss = mse(inp_imgs, similarity_multi_reduced_neurons)\n",
    "    \n",
    "    return loss, one_hot_imgs, generate_coords, similarity_multi_reduced_neurons, similarity_multi_max_batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, one_hot_imgs, generate_coords, similarity_multi_reduced_neurons, similarity_multi_max_batch  = test_fn(neuron_imgs_list, coords, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002\n"
     ]
    }
   ],
   "source": [
    "print(loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f04000b4780>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAC1ZJREFUeJzt3W+s3QV9x/H3Z62VgSNtXSC1xVGSBmdMFNMsoD4goJkyIzzADKNJt7D0yRbRLdGyPfLZSIzgg8WkgRmyLIKrZJA+kBCsyR513Mo2gVLLZClXqrAAuvhgseG7B+fX5KJ3nNN7zzn3XL7vV3Jz7u/0d+/vm1/6vr8/9/Q0VYWkXn5roweQNH+GLzVk+FJDhi81ZPhSQ4YvNWT4UkPrCj/Jx5OcSvJckkPTGkrSbGWtL+BJsgX4EfAxYBl4AvhMVT0zvfEkzcLWdXztHwDPVdWPAZI8ANwM/L/hJ/FlgtKMVVXGrbOeU/3dwAsrlpeH594gycEkS0mW1rEtSVO0niP+aj9VfuOIXlWHgcPgEV9aFOs54i8DV6xY3gO8uL5xJM3DesJ/AtiXZG+SbcBtwCPTGUvSLK35VL+qziX5C+BRYAvw91X19NQmkzQza/513po25jW+NHOzvqsvaZMyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnxpk6sqLvR9NQxfamg977IraQEkY99w5zd4xJcaMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qaGx4Se5IsmxJCeTPJ3kjuH5nUkeS3J6eNwx+3ElTUPGvVdXkl3Arqr6QZLfAU4AtwB/ArxSVX+b5BCwo6q+POZ7Xdgbg0m6YFU19i15xh7xq+psVf1g+Px/gJPAbuBm4P5htfsZ/TCQtAlc0DV+kiuBa4DjwOVVdRZGPxyAy6Y9nKTZmPjNNpO8A/gO8IWq+sWkb/CX5CBwcG3jSZqFsdf4AEneBhwFHq2qrw3PnQKur6qzw32A71fV1WO+j9f40oxN5Ro/o0P7fcDJ89EPHgEODJ8fAB5ey5CS5m+Su/ofAf4F+CHw+vD0XzO6zv828G7gDPDpqnplzPfyiC/N2CRH/IlO9afF8KXZm8qpvqS3HsOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKmhicNPsiXJk0mODst7kxxPcjrJg0m2zW5MSdN0IUf8O4CTK5bvAu6uqn3Aq8Dt0xxM0uxMFH6SPcAfAfcOywFuAI4Mq9wP3DKLASVN36RH/HuALwGvD8vvBF6rqnPD8jKwe7UvTHIwyVKSpXVNKmlqxoaf5JPAS1V1YuXTq6xaq319VR2uqv1VtX+NM0qasq0TrPNh4FNJbgIuAi5ldAawPcnW4ai/B3hxdmNKmqaxR/yqurOq9lTVlcBtwPeq6rPAMeDWYbUDwMMzm1LSVK3n9/hfBv4yyXOMrvnvm85IkmYtVatems9mY8n8NiY1VVWr3YN7A1+5JzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQxOFn2R7kiNJnk1yMsl1SXYmeSzJ6eFxx6yHlTQdkx7xvw58t6reA7wfOAkcAh6vqn3A48OypE0gVfXmKySXAv8OXFUrVk5yCri+qs4m2QV8v6quHvO93nxjktatqjJunUmO+FcBLwPfTPJkknuTXAJcXlVnhw2dBS5b17SS5maS8LcCHwS+UVXXAL/kAk7rkxxMspRkaY0zSpqyScJfBpar6viwfITRD4KfDaf4DI8vrfbFVXW4qvZX1f5pDCxp/caGX1U/BV5Icv76/UbgGeAR4MDw3AHg4ZlMKGnqxt7cA0jyAeBeYBvwY+BPGf3Q+DbwbuAM8OmqemXM9/HmnjRjk9zcmyj8aTF8afamdVdf0luM4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1NBE4Sf5YpKnkzyV5FtJLkqyN8nxJKeTPJhk26yHlTQdY8NPshv4PLC/qt4HbAFuA+4C7q6qfcCrwO2zHFTS9Ex6qr8V+O0kW4GLgbPADcCR4c/vB26Z/niSZmFs+FX1E+CrwBlGwf8cOAG8VlXnhtWWgd2rfX2Sg0mWkixNZ2RJ6zXJqf4O4GZgL/Au4BLgE6usWqt9fVUdrqr9VbV/PYNKmp5JTvU/CjxfVS9X1a+Ah4APAduHU3+APcCLM5pR0pRNEv4Z4NokFycJcCPwDHAMuHVY5wDw8GxGlDRtqVr1DP2NKyVfAf4YOAc8CfwZo2v6B4Cdw3Ofq6r/HfN9xm9M0rpUVcatM1H402L40uxNEr6v3JMaMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw9/kqop5/qcoemswfKmhreNX0SIb/T+m0oXxiC81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkPzfsnufwO/HB43g99l88wKm2vezTQrbJ55f2+SlTLvf9mVZKmq9s91o2u0mWaFzTXvZpoVNt+843iqLzVk+FJDGxH+4Q3Y5lptpllhc827mWaFzTfvm5r7Nb6kjeepvtTQ3MJP8vEkp5I8l+TQvLY7qSRXJDmW5GSSp5PcMTy/M8ljSU4Pjzs2etbzkmxJ8mSSo8Py3iTHh1kfTLJto2c8L8n2JEeSPDvs4+sWdd8m+eLwd+CpJN9KctEi79u1mEv4SbYAfwd8Angv8Jkk753Hti/AOeCvqur3gWuBPx9mPAQ8XlX7gMeH5UVxB3ByxfJdwN3DrK8Ct2/IVKv7OvDdqnoP8H5Gcy/cvk2yG/g8sL+q3gdsAW5jsffthTv/Lq2z/ACuAx5dsXwncOc8tr2OmR8GPgacAnYNz+0CTm30bMMsexjFcgNwFAijF5hsXW2fb/CslwLPM9xTWvH8wu1bYDfwArCT0QvcjgJ/uKj7dq0f8zrVP78zz1senltISa4ErgGOA5dX1VmA4fGyjZvsDe4BvgS8Piy/E3itqs4Ny4u0j68CXga+OVya3JvkEhZw31bVT4CvAmeAs8DPgRMs7r5dk3mFv9pbwS7krxOSvAP4DvCFqvrFRs+zmiSfBF6qqhMrn15l1UXZx1uBDwLfqKprGL1se8NP61cz3Ge4GdgLvAu4hNEl6q9blH27JvMKfxm4YsXyHuDFOW17Yknexij6f6yqh4anf5Zk1/Dnu4CXNmq+FT4MfCrJfwEPMDrdvwfYnuT8v79YpH28DCxX1fFh+QijHwSLuG8/CjxfVS9X1a+Ah4APsbj7dk3mFf4TwL7hzug2RjdLHpnTtieS0RvU3wecrKqvrfijR4ADw+cHGF37b6iqurOq9lTVlYz25feq6rPAMeDWYbWFmBWgqn4KvJDk6uGpG4FnWMB9y+gU/9okFw9/J87PupD7ds3meNPkJuBHwH8Cf7PRNzdWme8jjE7f/gP4t+HjJkbXzo8Dp4fHnRs966/NfT1wdPj8KuBfgeeAfwLevtHzrZjzA8DSsH//GdixqPsW+ArwLPAU8A/A2xd5367lw1fuSQ35yj2pIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGvo/xdPO/oV/yqkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tf.squeeze(neuron_imgs_list[0]), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f040af87208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tf.squeeze(np.sum(similarity_multi_max_batch, axis=0)), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f03a07600f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tf.squeeze(similarity_multi_reduced_neurons[1]), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 1, 2), dtype=float32, numpy=\n",
       "array([[[[3.9520926, 4.0238233]]],\n",
       "\n",
       "\n",
       "       [[[3.9520926, 4.0238233]]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 1, 2), dtype=float32, numpy=\n",
       "array([[[[38., 54.]]],\n",
       "\n",
       "\n",
       "       [[[51., 46.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer \n",
    "opt= tf.keras.optimizers.Adam(lr)\n",
    "#loss function \n",
    "mse = tf.losses.MeanSquaredError()\n",
    "@tf.function\n",
    "def train_fn(inp_imgs, coords, img_size):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        #normalizing the coordinates \n",
    "        norm_coords = coords/(img_size-1)\n",
    "        m1 = tf.constant([1,img_size, img_size,1], tf.int32) #multiplier for tiling \n",
    "        tile_cd = tf.tile(norm_coords, m1)\n",
    "        #deconv\n",
    "        de_coordconv.trainable = False #freeze de-coordconv\n",
    "        one_hot_imgs = tf.reshape(de_coordconv(tile_cd), [-1, img_size, img_size, 1])\n",
    "        #dot product\n",
    "        similarity_score = tf.tensordot(inp_imgs, one_hot_imgs, [[1,2,3],[1,2,3]])\n",
    "        #multiply similarity scores with one hot images\n",
    "        similarity_multi = tf.einsum('ij,jklm->ijklm', similarity_score, one_hot_imgs) #(batch_size, n_neurons, img_size, img_size,1)\n",
    "        #sum the one hot images for all neurons to compute MSE\n",
    "        similarity_multi_reduced_neurons = tf.math.reduce_sum(similarity_multi, axis=1)#(batch_size, img_size, img_size, 1)\n",
    "        similarity_multi_max_batch = tf.math.reduce_max(similarity_multi, axis = 0)#(n_neurons,img_size,mg_size,1)\n",
    "        #reconstruciton loss \n",
    "        loss = mse(inp_imgs, similarity_multi_reduced_neurons)\n",
    "        #generate coordinates from coordconv model \n",
    "        coordconv.trainable = True \n",
    "        generate_coords = coordconv(similarity_multi_max_batch)\n",
    "\n",
    "    #back prop through coordconv\n",
    "    grad = tape.gradient(loss, coordconv.trainable_variables)\n",
    "    opt.apply_gradients(zip(grad, coordconv.trainable_variables))\n",
    "    \n",
    "    return loss, generate_coords, one_hot_imgs, similarity_score, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    <ipython-input-11-74f285d8b045>:30 train_fn  *\n        opt.apply_gradients(zip(grad, coordconv.trainable_variables))\n    /home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:426 apply_gradients\n        grads_and_vars = _filter_grads(grads_and_vars)\n    /home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:1039 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['coord_conv_1/conv2d_6/kernel:0', 'coord_conv_1/conv2d_6/bias:0', 'conv2d_7/kernel:0', 'conv2d_7/bias:0', 'conv2d_8/kernel:0', 'conv2d_8/bias:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_10/kernel:0', 'conv2d_10/bias:0', 'conv2d_11/kernel:0', 'conv2d_11/bias:0', 'conv2d_12/kernel:0', 'conv2d_12/bias:0', 'conv2d_13/kernel:0', 'conv2d_13/bias:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-11e4ad1e8dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mupdated_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron_imgs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mupdated_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_coords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    495\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    496\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 497\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-11-74f285d8b045>:30 train_fn  *\n        opt.apply_gradients(zip(grad, coordconv.trainable_variables))\n    /home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:426 apply_gradients\n        grads_and_vars = _filter_grads(grads_and_vars)\n    /home/kevinteng/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:1039 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['coord_conv_1/conv2d_6/kernel:0', 'coord_conv_1/conv2d_6/bias:0', 'conv2d_7/kernel:0', 'conv2d_7/bias:0', 'conv2d_8/kernel:0', 'conv2d_8/bias:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_10/kernel:0', 'conv2d_10/bias:0', 'conv2d_11/kernel:0', 'conv2d_11/bias:0', 'conv2d_12/kernel:0', 'conv2d_12/bias:0', 'conv2d_13/kernel:0', 'conv2d_13/bias:0'].\n"
     ]
    }
   ],
   "source": [
    "steps = 0\n",
    "while steps<=1000:\n",
    "    if steps==0:\n",
    "        updated_coords = coords\n",
    "    loss, generate_coords, one_hot_imgs, similarity_score, grad = train_fn(neuron_imgs_list, updated_coords, IMG_SIZE)\n",
    "    updated_coords = generate_coords\n",
    "    \n",
    "    print(\"Loss: {}\".format(loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
