{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n",
      "HI\n",
      "5.0\n",
      "\n",
      "e\n",
      "HI\n",
      "15.0\n",
      "\n",
      "e\n",
      "HI\n",
      "20.0\n",
      "\n",
      "e\n",
      "HI\n",
      "25.0\n",
      "\n",
      "e\n",
      "HI\n",
      "30.0\n",
      "\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "test = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "def ran_func(inp, b):\n",
    "    print('HI')\n",
    "    a = inp*5\n",
    "    b+=a\n",
    "    c = np.mean(b)\n",
    "    return c\n",
    "\n",
    "for i, (img) in enumerate(test):\n",
    "    if i == 0:\n",
    "        print('d')\n",
    "        d =ran_func(img, 0)\n",
    "        print(d)\n",
    "        print()\n",
    "    if i >0 and i<5:\n",
    "        print('e')\n",
    "        e = ran_func(img, d)\n",
    "        print(e)\n",
    "        print()\n",
    "    continue\n",
    "    \n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils_model import img_mean, min_max_norm\n",
    "# #loss function\n",
    "# loss_fn = tf.losses.MeanSquaredError()\n",
    "# #loss_fn = lambda x,y: dice_coef_loss(x,y)\n",
    "# #loss_fn = lambda x,y: jaccard_distance_loss(x,y)\n",
    "\n",
    "# #annealer = lambda x: lr * 0.8 ** x\n",
    "# #optimizer \n",
    "# opt = tf.optimizers.Adam(lr)\n",
    "\n",
    "# max_step_num = int((len(re_list)*REPEAT)/BATCH_SIZE)\n",
    "# print('Total number of steps: ',max_step_num)\n",
    "# print()\n",
    "\n",
    "\n",
    "# dst = tf.data.Dataset.from_tensor_slices(re_list).repeat(10).batch(1)\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "# def train(inp, mean_roi, stack, i):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         if i != 605 -1:\n",
    "#             conv_img = model(inp) #(batch, img_size, img_size)\n",
    "#             stack+= tf.squeeze(conv_img)\n",
    "#             mean_img = 0\n",
    "#             xent = 0\n",
    "#             return xent, mean_img, stack\n",
    "#         else:\n",
    "#             conv_img = model(inp) #value (0,1) because of sigmoid\n",
    "#             stack+= tf.squeeze(conv_img)\n",
    "#             mean_img = stack/(i+1)\n",
    "#             mean_img = tf.expand_dims(mean_img, -1)\n",
    "            \n",
    "#         xent = loss_fn(mean_roi, mean_img)\n",
    "\n",
    "#     grads = tape.gradient(xent, model.trainable_variables)\n",
    "#     opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "#     return xent, mean_img, stack\n",
    "\n",
    "# ori_list = [] #original image list\n",
    "# de_list = [] #mean image fromt the network list\n",
    "# loss_list = [] #loss list\n",
    "\n",
    "# epochs = 0\n",
    "\n",
    "# while epochs < 5:\n",
    "#     print(epochs+1)\n",
    "#     #initialize stack in every new epochs or new data session\n",
    "#     stack = tf.zeros((200, 200))\n",
    "#     for step, (img_batch) in enumerate(dst):\n",
    "#         if step < 605:\n",
    "#             xent, conv_img, stack =train(img_batch, mean_roi, stack, i)\n",
    "#             continue\n",
    "#         xent, conv_img = train(img_batch, mean_roi)\n",
    "# #         ori_list.append(img_batch)\n",
    "#     de_list.append(conv_img)\n",
    "#     loss_list.append(xent)\n",
    "\n",
    "#     print(\"Epochs {:5d}, Loss: {}\".format(epochs, xent.numpy()))        \n",
    "#     epochs+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = lambda x: x*np.array([y for y in range(0,11)])\n",
    "\n",
    "print(z(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = np.array([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "test10 = test.repeat(10)\n",
    "\n",
    "z = lambda x: x*np.array([y for y in range(0,11)])\n",
    "\n",
    "b =np.array(0)\n",
    "\n",
    "def ran_func(inp, b, length):\n",
    "    print('HI')\n",
    "    a = inp*5\n",
    "    b+= a\n",
    "    c = b/length\n",
    "    return c,b\n",
    "\n",
    "for i, (img) in enumerate(test):\n",
    "    if i < len(test):\n",
    "        c, b =ran_func(img, b, len(test))\n",
    "    continue\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.array([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "test10 = test.repeat(10)\n",
    "\n",
    "z = lambda x: x*np.array([y for y in range(0,11)])\n",
    "\n",
    "\n",
    "def ran_func(inp, b, length):\n",
    "    #print('HI')\n",
    "    a = inp*5\n",
    "    b+= a\n",
    "    \n",
    "    # main idea stops here before parsing on to c\n",
    "    c = b/length\n",
    "    return c,b\n",
    "\n",
    "epochs = 0\n",
    "while epochs <2:\n",
    "    b =np.array(0)\n",
    "    for i, (img) in enumerate(test):\n",
    "        if i < len(test):\n",
    "            c, b =ran_func(img, b, len(test))\n",
    "            print(i)\n",
    "            print(b)\n",
    "            print(c)\n",
    "            continue\n",
    "    epochs+=1\n",
    "#     print(epochs)\n",
    "#     print(c, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test = np.array([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "test10 = test.repeat(10)\n",
    "\n",
    "z = lambda x: x*np.array([y for y in range(0,11)])\n",
    "\n",
    "\n",
    "def ran_func(inp, b, length, i):\n",
    "    if i != length-1:\n",
    "        a = inp*5\n",
    "        b+= a\n",
    "        mean = 0\n",
    "        print('Mean is None')\n",
    "        return mean, b\n",
    "    # main idea stops here before parsing on\n",
    "    else:\n",
    "        a = inp*5\n",
    "        b+= a\n",
    "        mean = b/length\n",
    "        print('Mean')\n",
    "        return mean, b\n",
    "\n",
    "epochs = 0\n",
    "while epochs <2:\n",
    "    b =np.array(0)\n",
    "    for i, (img) in enumerate(test):\n",
    "        if i < len(test):\n",
    "            mean, b = ran_func(img, b, len(test), i)\n",
    "            print(i)\n",
    "            if mean == 0:\n",
    "                print(b)\n",
    "            else:\n",
    "                print(mean)\n",
    "            continue\n",
    "    epochs+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dst = tf.data.Dataset.from_tensor_slices(re_list).repeat(2).batch(1)\n",
    "\n",
    "# def ran_func(inp, stack, i, mean_roi):\n",
    "#     if i!= 605 -1:\n",
    "#         conv_img = model(inp) #value (0,1) because of sigmoid\n",
    "#         stack+= tf.squeeze(conv_img)\n",
    "#         mean_img = 0\n",
    "#         loss = 0\n",
    "#         #print('Mean is None!')\n",
    "#         return loss, mean_img, stack\n",
    "#     else: \n",
    "#         conv_img = model(inp) #value (0,1) because of sigmoid\n",
    "#         stack+= tf.squeeze(conv_img)\n",
    "#         mean_img = stack/(i+1)\n",
    "#         mean_img = tf.expand_dims(mean_img, -1)\n",
    "        \n",
    "#         #print('Mean!')\n",
    "#     loss = utils.MSE_image(mean_roi, mean_img, 200)    \n",
    "#     return loss, mean_img,stack\n",
    "\n",
    "# # one epochs is one training of one data session\n",
    "# epochs = 0\n",
    "# while epochs <2:\n",
    "#     print(\"Epochs!:\",epochs+1)\n",
    "#     #initialize stack in every new epochs or new data session\n",
    "#     stack = tf.zeros((200, 200))\n",
    "#     #print(stack)\n",
    "#     for i, (img) in enumerate(dst):\n",
    "#         if i < 605:\n",
    "#             loss, mean_img, stack =ran_func(img, stack, i, mean_roi)\n",
    "#             if not i%4: \n",
    "#                 print(i)\n",
    "#                 print(\"Loss!: {}, Mean!: {}\".format(loss, mean_img))\n",
    "#                 print(stack)\n",
    "#                 print()\n",
    "# #             if mean_img != 0:\n",
    "# #                 print(i)\n",
    "# #                 print(np.max(mean_img))\n",
    "#             continue\n",
    "#     print(loss)\n",
    "#     epochs+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dst = tf.data.Dataset.from_tensor_slices(re_list).repeat(2).batch(1)\n",
    "\n",
    "\n",
    "# def stack_fn(inp, stack, i):\n",
    "#     print(i)\n",
    "#     conv_img = model(inp) #value (0,1) because of sigmoid\n",
    "#     stack+= tf.squeeze(conv_img)\n",
    "#     #print('Mean is None!')\n",
    "#     return stack\n",
    "\n",
    "# def train(inp, stack, mean_roi, i):\n",
    "#     print(i)\n",
    "#     conv_img = model(inp) #value (0,1) because of sigmoid\n",
    "#     stack+= tf.squeeze(conv_img)\n",
    "#     print('Mean!')\n",
    "#     mean_img = stack/(i+1)\n",
    "#     mean_img = tf.expand_dims(mean_img, -1)\n",
    "    \n",
    "#     loss = utils.MSE_image(mean_roi, mean_img, 200)    \n",
    "#     return loss, mean_img\n",
    "\n",
    "# # one epochs is one training of one data session\n",
    "# epochs = 0\n",
    "# while epochs <2:\n",
    "#     print(\"Epochs!:\",epochs+1)\n",
    "#     #initialize stack in every new epochs or new data session\n",
    "#     stack = tf.zeros((200, 200))\n",
    "#     #print(stack)\n",
    "#     for i, (img) in enumerate(dst):\n",
    "#         if i < 604:\n",
    "#             stack =stack_fn(img, stack, i)\n",
    "#             #print(stack)\n",
    "#             continue\n",
    "#         if i == 604:\n",
    "#             loss, mean_img = train(img, stack, mean_roi, i)\n",
    "#     print(loss)\n",
    "#     print(mean_img)\n",
    "#     epochs+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test = np.array([1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "test10 = test.repeat(10)\n",
    "\n",
    "z = lambda x: x*np.array([y for y in range(0,11)])\n",
    "\n",
    "\n",
    "def ran_func(inp, b, length, i):\n",
    "    a = inp*5\n",
    "    b+= a\n",
    "    mean = 0\n",
    "    print('Mean is None')\n",
    "    if i== length-1:\n",
    "        mean = b/length\n",
    "        print('Mean!')\n",
    "    return mean, b\n",
    "\n",
    "epochs = 0\n",
    "while epochs <2:\n",
    "    b =np.array(0)\n",
    "    for i, (img) in enumerate(test):\n",
    "        if i < len(test):\n",
    "            mean, b = ran_func(img, b, len(test), i)\n",
    "            print(mean, b)\n",
    "            continue\n",
    "    epochs+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
